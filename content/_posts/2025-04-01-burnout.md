---
title: Addressing Burnout
author: Libera.Chat Staff
---

>Update: This was our April 1st 2025 prank. It was a reminder that burnout is
>real, especially in volunteer efforts, and that it has no easy answers. This
>is also a protest about the social burden created by LLMs - often trained
>using questionable ethics - including on the quality of support resources.
>And sometimes with the ultimate goal of replacing real human interactions
>that make communities like ours so special. <3

<!-- markdownlint-disable MD033 -->
<picture>
    <source srcset="/static/img/aprildark.png"
    media="(prefers-color-scheme: dark)">
    <img class="feature" alt="Introducing APRIL"
    src="/static/img/aprilbright.png" data-proofer-ignore>
</picture>
<!-- markdownlint-restore -->

Hello Libera.Chat users,

There's no easy way to say this, so here it is: staff are burned out.
Many of us are facing heightened pressures at work which leave us with
insufficient time and energy to maintain Libera.Chat.
This has been a problem for a while now, but this year we are finally choosing
to acknowledge it and evaluate potential solutions.

Upon review, we found that a significant portion of staff time is consumed by
answering support queries in `#libera`. As a channel that is often visited by
newcomers to the network, many of the questions tend to be similar in nature.
We're thankful for the community of helpers in `#libera` who help us help you
help us all, but there are some support matters which the helpers simply
lack the privileges to assist with.

In order to reduce support load, we have decided to do a trial run of
LLM-based support scripts. Historically we have been reluctant to make use of
machine learning in our tooling, but we're not unreasonable, and the latest
large language models are capable of replacing subject matter experts,
just like every generation of LLMs since GPT3. We have been assured by
key figures in the software development industry that long-standing issues
with hallucinations have been worked out and that the amount of effort needed
for human review is now an order of magnitude less than the amount of effort
needed for a human to do those same tasks in the first place.

Using state-of-the-art technology allows us to provide the models with
full access to privileged staff interfaces without facing risks from
adversarial inputs or prompt injection, so that they can even assist you in
tasks that would previously have required a staff member to manually issue
privileged commands. To alleviate any worries about disruptive or harmful
actions taken by the LLM scripts, we have implemented a system of
checks and balances where several different LLMs will be keeping tabs on
each other by conversing in a private IRC channel inhabited purely by
LLM staff members. Going forward, we hope to implement automated testing where
LLM-powered guests will message the support scripts and
evaluate the resulting actions.

Staffers running these scripts will have auto-generated responses prefixed
with `[LLM]` in compliance with [our LLM etiquette][llmguide].
These scripts will only reply to certain private messages and messages in
`#libera`. Please note that we will be running these LLMs under
tight resource constraints for ethical reasons. Additionally, they are trained
exclusively on our staff members' collective brainwaves, and absolutely no
user data or logs have been processed by the model nor will be collected.
As a result, these scripts will exhibit delayed responses, may occasionally
not respond at all, and will sometimes generate contradictory nonsense.
Despite this, we believe that using our new in-house model, APRIL v01, is the
best option to ensure the availability of support on Libera.Chat.

After ensuring the scripts are functional, some members of staff have
expressed an intent to take a short break from their usual duties. If you wish
to learn more about APRIL and discuss the use of LLMs in this context,
please join us in our computer-aided enrichment center, `#libera-april`.

[llmguide]: https://libera.chat/news/llm-etiquette
